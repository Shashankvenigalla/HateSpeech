{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c963f9-6639-4740-b30b-652b3febb9b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea07de-f634-47e9-897c-6732f18e559e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e274e95-fa83-4613-a917-1fea7543bdcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da1956-db8e-4322-88d0-c35afd67e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing all necessary Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "import shap\n",
    "#import lime.lime_text\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "print(\" All required libraries installed succesfully!!!!...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3544b570-94e8-4a44-8538-30227a1eefc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "labeled_data = pd.read_csv('labeled_data.csv')\n",
    "emoji_sentiment = pd.read_excel('emoji_sentiment.xlsx')\n",
    "print(\"All datasets loaded sucessfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a07a61-88c7-448d-b28d-16c1ff59b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847594fb-ee7e-4356-9294-94035f2dd532",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data['clean_text'] = labeled_data['tweet'].apply(clean_text)  # Fixed column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82273ad8-283f-4e2a-8ab3-8998980f20fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "labeled_data['label'] = label_encoder.fit_transform(labeled_data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90400cf5-3022-4cb1-8d8e-cbd750436f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(labeled_data['clean_text'], labeled_data['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ee50f8-eb68-4a53-bb13-41d397696a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction (TF-IDF)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7246e4c-62ff-49b8-9d62-32d791c6596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83226a5-f188-46dd-8bec-1cd192aeca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embeddings (Word2Vec)\n",
    "tokenized_texts = [text.split() for text in X_train]\n",
    "word2vec_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34d5ba-7a70-4e5d-b52a-fb9d8416dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Embeddings\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c46929-88b2-4638-b5a6-f00db069a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(texts):\n",
    "    tokens = tokenizer(texts, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "    outputs = bert_model(tokens['input_ids'])\n",
    "    return outputs.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62123f5-01d6-4430-9673-15bb08da2f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bert = get_bert_embeddings(X_train.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca6678-ddc0-497e-a363-15c318fe4b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(texts):\n",
    "    tokens = tokenizer(texts, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "    outputs = bert_model(tokens['input_ids'])\n",
    "    return outputs.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36507ae2-75d0-4d2d-a3cf-7f2d2d4c78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bert = get_bert_embeddings(X_train.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45478708-11d0-467a-ab10-c4cfc1588036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing Data with SMOTE and Undersampling\n",
    "smote = SMOTE(random_state=42)\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train_tfidf, y_train)\n",
    "X_train_bal, y_train_bal = rus.fit_resample(X_train_bal, y_train_bal)\n",
    "print(\"Balanced dataset shape:\", Counter(y_train_bal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e42c3d-3375-4cb5-a4a9-ad303199d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Development (Hybrid CNN-RNN)\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128, input_length=X_train_tfidf.shape[1]),\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a874c5c-24f8-464f-91a8-d536a7373c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ff3f3-14e0-488d-b0c2-3ff07a9a5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "model.fit(X_train_bal.toarray(), y_train_bal, epochs=10, batch_size=32, validation_data=(X_test_tfidf.toarray(), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0726a9-9837-448d-80f2-9a0e75001199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "eval_results = model.evaluate(X_test_tfidf.toarray(), y_test)\n",
    "print(f\"Test Accuracy: {eval_results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30253a7-2eb8-42b6-8a48-b57cde3aaff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explainability (SHAP & LIME)\n",
    "explainer = shap.Explainer(model, X_test_tfidf.toarray())\n",
    "shap_values = explainer(X_test_tfidf.toarray())\n",
    "shap.summary_plot(shap_values, X_test_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68cbc6-3bd8-42df-82dd-f4523386ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explainer = lime.lime_text.LimeTextExplainer(class_names=label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de9aac-44a3-4645-99d0-6927aaec6b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model successfully trained and evaluated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b038e6c0-79c1-45be-addd-f69a8858b390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a94c6-9229-41ad-b09a-a449bfd3946f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda128e6-76bf-4186-98bf-fdc318ec237c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
